{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EndrikM/Capstone-Projekt/blob/main/Capstone_Algorithmus.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OZCGeO4hVuWC"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "\n",
        "\n",
        "class DataManager:\n",
        "    def __init__(self) -> None:\n",
        "        self._file_path = \"data.json\"\n",
        "\n",
        "        if not os.path.exists(self._file_path):\n",
        "            self._store({})\n",
        "\n",
        "        self._data: dict[str, tuple[str, str]] = self._load()\n",
        "\n",
        "    def get_data(self) -> dict[str, tuple[str, str]]:\n",
        "        return self._data.copy()\n",
        "\n",
        "    def add_all_urls(self, urls: dict[str, tuple[str, str]], update_existing: bool) -> None:\n",
        "        for name, (label, url) in urls.items():\n",
        "            if update_existing or (name not in self._data):\n",
        "                self.add_url(name, label, url)\n",
        "\n",
        "    def add_url(self, name: str, label: str, url: str) -> None:\n",
        "        text = self._get_text_from_url(url)\n",
        "        text = text.replace(\"\\xa0\", \" \")\n",
        "        text = text.replace(\"\\t\", \" \")\n",
        "        text = text.strip()\n",
        "        if len(text) == 0:\n",
        "            print(\n",
        "                f\"The text for the URL {url} is empty or could not be loaded! Please check the URL.\")\n",
        "            return\n",
        "\n",
        "        self._data[name] = (label, text)\n",
        "        self._store(self._data)\n",
        "\n",
        "    def _get_text_from_url(self, url: str) -> str:\n",
        "        try:\n",
        "            headers = {\n",
        "                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
        "            }\n",
        "            response = requests.get(url, headers=headers)\n",
        "            response.raise_for_status()\n",
        "            soup = BeautifulSoup(response.content, 'html.parser')\n",
        "            paragraphs = soup.find_all('p')\n",
        "            text = ' '.join(p.get_text() for p in paragraphs)\n",
        "            return text\n",
        "        except Exception as e:\n",
        "            print(f\"Error retrieving the URL {url}: {e}\")\n",
        "            return \"\"\n",
        "\n",
        "    def _store(self, data: dict[str, tuple[str, str]]) -> None:\n",
        "        with open(self._file_path, \"w\", encoding=\"utf-8\") as file:\n",
        "            json.dump(data, file, ensure_ascii=False)\n",
        "\n",
        "    def _load(self) -> dict[str, tuple[str, str]]:\n",
        "        with open(self._file_path, \"r\", encoding=\"utf-8\") as file:\n",
        "            return json.load(file)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rhif_0FKVys2"
      },
      "outputs": [],
      "source": [
        "data_manager = DataManager()\n",
        "\n",
        "urls = {\n",
        "    \"whitehouse\": (\"Legal & Regulatory aspects of AI\", \"https://www.whitehouse.gov/briefing-room/presidential-actions/2023/10/30/executive-order-on-the-safe-secure-and-trustworthy-development-and-use-of-artificial-intelligence/?utm_source=chatgpt.com\"),\n",
        "    \"kpmg\": (\"Legal & Regulatory aspects of AI\", \"https://kpmg.com/us/en/articles/2023/landmark-actions-coming-the-ai-act-and-growing-us-regulations-reg-alert.html\"),\n",
        "    \"technologyreview\": (\"Legal & Regulatory aspects of AI\", \"https://www.technologyreview.com/2024/02/15/1087815/responsible-technology-use-in-the-ai-age/#:~:text=AI%20presents%20distinct%20social%20and,singular%20opportunity%20for%20responsible%20adoption.&text=The%20sudden%20appearance%20of%20application,challenging%20social%20and%20ethical%20questions.\"),\n",
        "    \"pwc\": (\"Legal & Regulatory aspects of AI\", \"https://www.pwc.ch/en/insights/regulation/ai-act-demystified.html\"),\n",
        "    \"bbc\": (\"Legal & Regulatory aspects of AI\", \"https://www.bbc.com/news/technology-68546450\"),\n",
        "    \"european comission\": (\"Legal & Regulatory aspects of AI\", \"https://digital-strategy.ec.europa.eu/en/policies/regulatory-framework-ai\"),\n",
        "    \"pecan\": (\"Next-Generation Regression Models and Data Calculation Algorithms\", \"https://www.pecan.ai/blog/predictive-modeling/\"),\n",
        "    \"databricks\": (\"Next-Generation Regression Models and Data Calculation Algorithms\", \"https://www.databricks.com/blog/introduction-time-series-forecasting-generative-ai\"),\n",
        "    \"bostoninstituteofanalytics\": (\"Next-Generation Regression Models and Data Calculation Algorithms\", \"https://bostoninstituteofanalytics.org/blog/the-role-of-ai-in-predictive-analytics-how-machine-learning-is-transforming-forecasting/\"),\n",
        "    \"discoverdatascience\": (\"Next-Generation Regression Models and Data Calculation Algorithms\", \"https://www.discoverdatascience.org/articles/breaking-down-the-top-data-science-algorithms-methods/\"),\n",
        "    \"pickl\": (\"Next-Generation Regression Models and Data Calculation Algorithms\", \"https://www.pickl.ai/blog/regression-in-machine-learning-types-examples/\"),\n",
        "    \"nature\": (\"Next-Generation Regression Models and Data Calculation Algorithms\", \"https://www.nature.com/articles/s41598-024-55243-x\"),\n",
        "    \"ibm\": (\"Large Language Models (LLMs) and Generative AI\", \"https://www.ibm.com/blog/generative-ai-vs-predictive-ai-whats-the-difference/\"),\n",
        "    \"computerworld\": (\"Large Language Models (LLMs) and Generative AI\", \"https://www.computerworld.com/article/1627101/what-are-large-language-models-and-how-are-they-used-in-generative-ai.html\"),\n",
        "    \"toloka\": (\"Large Language Models (LLMs) and Generative AI\", \"https://toloka.ai/blog/difference-between-ai-ml-llm-and-generative-ai/\"),\n",
        "    \"ieeexplore\": (\"Large Language Models (LLMs) and Generative AI\", \"https://ieeexplore.ieee.org/abstract/document/10669603\"),\n",
        "    \"mckinsey\": (\"Large Language Models (LLMs) and Generative AI\", \"https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/the-economic-potential-of-generative-ai-the-next-productivity-frontier\"),\n",
        "    \"appian\": (\"Large Language Models (LLMs) and Generative AI\", \"https://appian.com/blog/acp/process-automation/generative-ai-vs-large-language-models\"),\n",
        "    \"leewayhertz\": (\"Predictive Analytics and Forecasting\", \"https://www.leewayhertz.com/ai-for-predictive-analytics/\"),\n",
        "    \"mckinsey\": (\"Predictive Analytics and Forecasting\", \"https://www.mckinsey.com/capabilities/operations/our-insights/ai-driven-operations-forecasting-in-data-light-environments\"),\n",
        "    \"forbes\": (\"Predictive Analytics and Forecasting\", \"https://www.forbes.com/sites/amazonwebservices/2021/12/03/predicting-the-future-of-demand-how-amazon-is-reinventing-forecasting-with-machine-learning/\"),\n",
        "    \"dlabi\": (\"Predictive Analytics and Forecasting\", \"https://dlabi.org/index.php/journal/article/view/115\"),\n",
        "    \"geniusee\": (\"Predictive Analytics and Forecasting\", \"https://geniusee.com/single-blog/ai-and-predictive-analytics\"),\n",
        "    \"SAP\": (\"Predictive Analytics and Forecasting\", \"https://learning.sap.com/learning-journeys/leveraging-sap-analytics-cloud-functionality-for-enterprise-planning/forecasting-with-predictive-analytics_de7bdcb3-f8eb-4dca-bac1-00ebef2b7bee\"),\n",
        "    \"thomsonreuters\": (\"Ethics and Responsible Usage\", \"https://legal.thomsonreuters.com/blog/how-to-responsibly-use-ai-to-address-ethical-and-risk-challenges/\"),\n",
        "    \"ssir\": (\"Ethics and Responsible Usage\", \"https://ssir.org/articles/entry/8_steps_nonprofits_can_take_to_adopt_ai_responsibly\"),\n",
        "    \"atlassian\": (\"Ethics and Responsible Usage\", \"https://www.atlassian.com/blog/artificial-intelligence/responsible-ai\"),\n",
        "    \"springer-s10676-021-09606-x\": (\"Ethics and Responsible Usage\", \"https://link.springer.com/article/10.1007/s10676-021-09606-x\"),\n",
        "    \"springer-s43681-023-00330-4\": (\"Ethics and Responsible Usage\", \"https://link.springer.com/article/10.1007/s43681-023-00330-4\"),\n",
        "    \"forbes\": (\"Ethics and Responsible Usage\", \"https://www.forbes.com/councils/forbestechcouncil/2024/11/08/navigating-the-ethics-of-ai-is-it-fair-and-responsible-enough-to-use/\")\n",
        "}\n",
        "\n",
        "data_manager.add_all_urls(urls, update_existing=False)\n",
        "\n",
        "data = data_manager.get_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3bAuoVhcV3u6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21f956dd-f13d-41c2-f738-b34771f1b52e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "                                                                   precision    recall  f1-score   support\n",
            "\n",
            "                                     Ethics and Responsible Usage       0.25      0.50      0.33         2\n",
            "                   Large Language Models (LLMs) and Generative AI       0.00      0.00      0.00         2\n",
            "                                 Legal & Regulatory aspects of AI       1.00      0.50      0.67         2\n",
            "Next-Generation Regression Models and Data Calculation Algorithms       0.50      0.50      0.50         2\n",
            "                             Predictive Analytics and Forecasting       0.50      1.00      0.67         1\n",
            "\n",
            "                                                         accuracy                           0.44         9\n",
            "                                                        macro avg       0.45      0.50      0.43         9\n",
            "                                                     weighted avg       0.44      0.44      0.41         9\n",
            "\n",
            "Accuracy: 1.0\n",
            "Do Cross-Validation:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-Validation Scores: [0.6        0.55555556 0.55555556]\n",
            "Average Accuracy: 0.5703703703703703\n",
            "The predicted trend for the URL is: Large Language Models (LLMs) and Generative AI\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "# Function to extract Text from Websites\n",
        "\n",
        "def get_text_from_url(url):\n",
        "    try:\n",
        "        headers = {\n",
        "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
        "        }\n",
        "        response = requests.get(url, headers=headers)\n",
        "        response.raise_for_status()\n",
        "        soup = BeautifulSoup(response.content, 'html.parser')\n",
        "        paragraphs = soup.find_all('p')\n",
        "        text = ' '.join(p.get_text() for p in paragraphs)\n",
        "        return text\n",
        "    except Exception as e:\n",
        "        print(f\"Error retrieving the URL {url}: {e}\")\n",
        "        return \"\"\n",
        "\n",
        "\n",
        "\n",
        "# Load data from data.json file\n",
        "data_manager = DataManager()\n",
        "data = data_manager.get_data()\n",
        "labels, texts = zip(*(data.values()))\n",
        "\n",
        "# Create DataFrame\n",
        "df = pd.DataFrame({'text': texts, 'label': labels})\n",
        "\n",
        "# Transform Text into Features (TF-IDF)\n",
        "vectorizer = TfidfVectorizer(\n",
        "    max_features=5000, ngram_range=(1, 2), stop_words='english')\n",
        "X = vectorizer.fit_transform(df['text'])\n",
        "y = df['label']\n",
        "\n",
        "# Train-Test-Split\n",
        "try:\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.3, random_state=42, stratify=y\n",
        "    )\n",
        "except ValueError:\n",
        "    print(\"Warning: Not enough data for stratified split. Perform a normal split instead.\")\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "\n",
        "# Model training\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluation\n",
        "y_pred = model.predict(X_test)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_test))\n",
        "\n",
        "# Cross-Validation\n",
        "print(\"Do Cross-Validation:\")\n",
        "scores = cross_val_score(model, X, y, cv=3)\n",
        "print(\"Cross-Validation Scores:\", scores)\n",
        "print(\"Average Accuracy:\", scores.mean())\n",
        "\n",
        "# Example: Analyze a new URL\n",
        "new_url = \"https://www.nvidia.com/en-us/glossary/large-language-models/\"\n",
        "new_text = get_text_from_url(new_url)\n",
        "if new_text:\n",
        "    new_text_vectorized = vectorizer.transform([new_text])\n",
        "    predicted_trend = model.predict(new_text_vectorized)\n",
        "    print(f\"The predicted trend for the URL is: {predicted_trend[0]}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OAmLaVEDg1jt"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}